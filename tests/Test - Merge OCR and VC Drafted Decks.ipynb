{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1b2c3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cube list: dimlas5_cardlist.csv — 540/540 cards with scryfall ID\n",
      "✓ All cards have a scryfall ID.\n"
     ]
    }
   ],
   "source": [
    "# Test - Merge OCR and VC Drafted Decks\n",
    "# Compares OCR-validated deck lists against VC drafted_decks data.\n",
    "# Requires: pip install pandas requests\n",
    "\n",
    "import re, glob, os, time\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "BASE_DIR       = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "DRAFT_DATA_DIR = os.path.join(BASE_DIR, 'Draft csv data')\n",
    "CARDLIST_DIR   = os.path.join(BASE_DIR, 'data', 'cardlist')\n",
    "OUTPUT_DIR     = os.path.join(os.getcwd(), 'output')\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# ── Load cube list (name ↔ scryfall_id lookup) ──\n",
    "cube_lists = sorted(\n",
    "    glob.glob(os.path.join(CARDLIST_DIR, 'dimlas*_cardlist.csv')),\n",
    "    key=lambda f: int(re.search(r'dimlas(\\d+)_cardlist', f).group(1)),\n",
    "    reverse=True\n",
    ")\n",
    "if not cube_lists:\n",
    "    raise FileNotFoundError(f'No dimlas*_cardlist.csv found in {CARDLIST_DIR}')\n",
    "\n",
    "df_cube = pd.read_csv(cube_lists[0]).dropna(subset=['scryfall_id'])\n",
    "id_to_name = dict(zip(df_cube['scryfall_id'], df_cube['name'].str.strip()))\n",
    "name_to_id = {v: k for k, v in id_to_name.items()}\n",
    "\n",
    "total = len(pd.read_csv(cube_lists[0]))\n",
    "found = len(id_to_name)\n",
    "print(f'Cube list: {os.path.basename(cube_lists[0])} — {found}/{total} cards with scryfall ID')\n",
    "if found == total:\n",
    "    print('✓ All cards have a scryfall ID.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2c3d4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR folder: 20260125_Draft_7\n",
      "  345 cards from 12 players\n",
      "\n",
      "VC file: 2026_01_25_drafted_decks.csv\n",
      "  345 cards from 12 players\n",
      "\n",
      "✓ Card counts match: 345 cards in both sources.\n"
     ]
    }
   ],
   "source": [
    "# ── Load both sources ────────────────────────────────────────────────────────\n",
    "\n",
    "# 1) OCR: clean_*.csv from newest draft folder in data/clean/\n",
    "CLEAN_DIR = os.path.join(BASE_DIR, 'data', 'clean')\n",
    "clean_draft_folders = sorted(\n",
    "    [d for d in glob.glob(os.path.join(CLEAN_DIR, '*')) if os.path.isdir(d)],\n",
    "    reverse=True\n",
    ")\n",
    "if not clean_draft_folders:\n",
    "    raise FileNotFoundError(f'No draft folders found in {CLEAN_DIR}')\n",
    "newest_clean = clean_draft_folders[0]\n",
    "print(f'OCR folder: {os.path.basename(newest_clean)}')\n",
    "\n",
    "ocr_frames = []\n",
    "for f in sorted(glob.glob(os.path.join(newest_clean, 'clean_*.csv'))):\n",
    "    player = os.path.basename(f).replace('clean_', '').replace('.csv', '')\n",
    "    df = pd.read_csv(f)\n",
    "    df.columns = df.columns.str.strip().str.lower()\n",
    "    df['player'] = player\n",
    "    ocr_frames.append(df[['player', 'name']])\n",
    "\n",
    "if not ocr_frames:\n",
    "    raise FileNotFoundError(f'No clean_*.csv files found in {newest_clean}')\n",
    "\n",
    "df_ocr = pd.concat(ocr_frames, ignore_index=True)\n",
    "df_ocr.columns = ['player', 'card_name']\n",
    "df_ocr['card_name'] = df_ocr['card_name'].str.strip()\n",
    "print(f'  {len(df_ocr)} cards from {df_ocr[\"player\"].nunique()} players')\n",
    "\n",
    "# 2) VC: newest drafted_decks.csv → resolve scryfallId to card name\n",
    "DRAFT_DATA_DIR = os.path.join(BASE_DIR, 'Draft csv data')\n",
    "drafted = sorted(glob.glob(os.path.join(DRAFT_DATA_DIR, '*_drafted_decks.csv')), reverse=True)\n",
    "if not drafted:\n",
    "    raise FileNotFoundError('No *_drafted_decks.csv found')\n",
    "print(f'\\nVC file: {os.path.basename(drafted[0])}')\n",
    "\n",
    "df_vc = pd.read_csv(drafted[0])[['player', 'scryfallId']].copy()\n",
    "df_vc.columns = ['player', 'scryfall_id']\n",
    "df_vc['player']    = df_vc['player'].str.strip()\n",
    "df_vc['card_name'] = df_vc['scryfall_id'].map(id_to_name)\n",
    "\n",
    "# Batch-fetch any IDs not in the cube list (old printings / swapped cards)\n",
    "missing_ids = df_vc.loc[df_vc['card_name'].isna(), 'scryfall_id'].unique().tolist()\n",
    "if missing_ids:\n",
    "    print(f'  Fetching {len(missing_ids)} IDs not in cube list from Scryfall...')\n",
    "    api_map = {}\n",
    "    for i in range(0, len(missing_ids), 75):\n",
    "        batch = missing_ids[i:i+75]\n",
    "        resp = requests.post('https://api.scryfall.com/cards/collection',\n",
    "                             json={'identifiers': [{'id': s} for s in batch]}, timeout=30)\n",
    "        resp.raise_for_status()\n",
    "        for card in resp.json().get('data', []):\n",
    "            api_map[card['id']] = card['name'].split(' // ')[0].strip()\n",
    "        time.sleep(0.1)\n",
    "    df_vc['card_name'] = df_vc.apply(\n",
    "        lambda r: api_map.get(r['scryfall_id'], r['card_name']) if pd.isna(r['card_name']) else r['card_name'], axis=1)\n",
    "    print(f'  Resolved {len(api_map)}/{len(missing_ids)} via API')\n",
    "\n",
    "df_vc = df_vc[['player', 'card_name', 'scryfall_id']].dropna(subset=['card_name'])\n",
    "print(f'  {len(df_vc)} cards from {df_vc[\"player\"].nunique()} players')\n",
    "\n",
    "# ── Card count warning ────────────────────────────────────────────────────────\n",
    "if len(df_ocr) != len(df_vc):\n",
    "    print(f'\\n⚠ WARNING: Card count mismatch — OCR has {len(df_ocr)} cards, VC has {len(df_vc)} cards (difference: {abs(len(df_ocr) - len(df_vc))})')\n",
    "else:\n",
    "    print(f'\\n✓ Card counts match: {len(df_ocr)} cards in both sources.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3d4e5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Draft file : 2026_01_25_drafted_decks.csv\n",
      "Final file : 20260125_Draft_7.csv\n",
      "\n",
      "Cards in both      : 345\n",
      "In draft only      : 0\n",
      "In final only      : 0\n",
      "\n",
      "✓ Perfect match — both files contain the same cards.\n"
     ]
    }
   ],
   "source": [
    "# ── Compare newest Draft csv data file vs newest data/final file ──────────────\n",
    "\n",
    "DRAFT_CSV_DIR = os.path.join(BASE_DIR, 'Draft csv data')\n",
    "FINAL_DIR     = os.path.join(BASE_DIR, 'data', 'final')\n",
    "\n",
    "# Find newest file by modification time in each directory\n",
    "draft_files = sorted(glob.glob(os.path.join(DRAFT_CSV_DIR, '*_drafted_decks.csv')),\n",
    "                     key=os.path.getmtime, reverse=True)\n",
    "final_files = sorted(glob.glob(os.path.join(FINAL_DIR, '*.csv')),\n",
    "                     key=os.path.getmtime, reverse=True)\n",
    "\n",
    "if not draft_files:\n",
    "    raise FileNotFoundError(f'No *_drafted_decks.csv found in {DRAFT_CSV_DIR}')\n",
    "if not final_files:\n",
    "    raise FileNotFoundError(f'No CSV files found in {FINAL_DIR}')\n",
    "\n",
    "newest_draft = draft_files[0]\n",
    "newest_final = final_files[0]\n",
    "print(f'Draft file : {os.path.basename(newest_draft)}')\n",
    "print(f'Final file : {os.path.basename(newest_final)}')\n",
    "\n",
    "df_draft = pd.read_csv(newest_draft)\n",
    "df_final = pd.read_csv(newest_final)\n",
    "\n",
    "draft_ids = set(df_draft['scryfallId'].dropna())\n",
    "final_ids = set(df_final['scryfallId'].dropna())\n",
    "\n",
    "in_draft_only = draft_ids - final_ids\n",
    "in_final_only = final_ids - draft_ids\n",
    "in_both       = draft_ids & final_ids\n",
    "\n",
    "print(f'\\nCards in both      : {len(in_both)}')\n",
    "print(f'In draft only      : {len(in_draft_only)}')\n",
    "print(f'In final only      : {len(in_final_only)}')\n",
    "\n",
    "if in_draft_only:\n",
    "    print('\\n── In Draft but not in Final ──')\n",
    "    rows = df_draft[df_draft['scryfallId'].isin(in_draft_only)][['player', 'scryfallId']].drop_duplicates()\n",
    "    display(rows.reset_index(drop=True))\n",
    "\n",
    "if in_final_only:\n",
    "    print('\\n── In Final but not in Draft ──')\n",
    "    rows = df_final[df_final['scryfallId'].isin(in_final_only)][['player', 'scryfallId']].drop_duplicates()\n",
    "    display(rows.reset_index(drop=True))\n",
    "\n",
    "if not in_draft_only and not in_final_only:\n",
    "    print('\\n✓ Perfect match — both files contain the same cards.')\n",
    "else:\n",
    "    print(f'\\n⚠ WARNING: {len(in_draft_only)} card(s) in draft only, {len(in_final_only)} card(s) in final only.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
